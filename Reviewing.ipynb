{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "class DataCleaner:\n",
    "    @staticmethod\n",
    "    def load_and_clean_shifts(df):\n",
    "        \"\"\"Load and clean shifts dataset\"\"\"\n",
    "        df = df.copy()\n",
    "        datetime_cols = ['Start', 'End', 'Created At']\n",
    "        for col in datetime_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_datetime(df[col], format='mixed')\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_clean_bookings(df):\n",
    "        \"\"\"Load and clean booking logs dataset\"\"\"\n",
    "        df = df.copy()\n",
    "        df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_clean_cancellations(df):\n",
    "        \"\"\"Load and clean cancellation logs dataset\"\"\"\n",
    "        df = df.copy()\n",
    "        df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "        df['Shift Start Logs'] = pd.to_datetime(df['Shift Start Logs'])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def categorize_lead_time(hours):\n",
    "        \"\"\"Categorize lead times based on business rules\"\"\"\n",
    "        if hours < 0:\n",
    "            return 'No-Show'\n",
    "        elif hours < 4:\n",
    "            return 'Late (<4hrs)'\n",
    "        elif hours < 24:\n",
    "            return 'Same Day'\n",
    "        elif hours < 72:\n",
    "            return 'Advance (<3 days)'\n",
    "        return 'Early (3+ days)'\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_lead_times(df):\n",
    "        \"\"\"Clean and categorize lead times in cancellation data\"\"\"\n",
    "        df = df.copy()\n",
    "        quality_stats = {\n",
    "            'original_rows': len(df),\n",
    "            'null_lead_times': df['Lead Time'].isnull().sum(),\n",
    "            'infinite_values': (~np.isfinite(df['Lead Time'])).sum()\n",
    "        }\n",
    "        \n",
    "        mask = df['Lead Time'].notnull() & np.isfinite(df['Lead Time'])\n",
    "        df = df[mask]\n",
    "        df['clean_lead_time'] = df['Lead Time']\n",
    "        df['cancellation_category'] = df['clean_lead_time'].apply(DataCleaner.categorize_lead_time)\n",
    "        \n",
    "        df['is_extreme_negative'] = df['Lead Time'] < -72\n",
    "        df['is_extreme_positive'] = df['Lead Time'] > 1000\n",
    "        \n",
    "        quality_stats['final_rows'] = len(df)\n",
    "        quality_stats['removed_rows'] = quality_stats['original_rows'] - quality_stats['final_rows']\n",
    "        \n",
    "        return df, pd.Series(quality_stats)\n",
    "\n",
    "class DataAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.summaries = {}\n",
    "\n",
    "    def analyze_cancellation_patterns(self, clean_cancellations, shifts_df):\n",
    "        \"\"\"Analyze patterns in cancellations\"\"\"\n",
    "        action_counts = clean_cancellations['Action'].value_counts()\n",
    "        \n",
    "        cancellations_with_shifts = pd.merge(\n",
    "            clean_cancellations,\n",
    "            shifts_df[['ID', 'Agent Req', 'Shift Type', 'Charge']],\n",
    "            left_on='Shift ID',\n",
    "            right_on='ID',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        role_cancels = pd.crosstab(\n",
    "            cancellations_with_shifts['Agent Req'],\n",
    "            cancellations_with_shifts['cancellation_category'],\n",
    "            normalize='index'\n",
    "        ).round(3) * 100\n",
    "        \n",
    "        shift_cancels = pd.crosstab(\n",
    "            cancellations_with_shifts['Shift Type'],\n",
    "            cancellations_with_shifts['cancellation_category'],\n",
    "            normalize='index'\n",
    "        ).round(3) * 100\n",
    "        \n",
    "        self.summaries['cancellations'] = {\n",
    "            'action_types': action_counts.to_dict(),\n",
    "            'role_patterns': role_cancels.to_dict(),\n",
    "            'shift_patterns': shift_cancels.to_dict()\n",
    "        }\n",
    "        \n",
    "        return cancellations_with_shifts\n",
    "\n",
    "    def analyze_booking_patterns(self, bookings_df, shifts_df, clean_cancellations):\n",
    "        \"\"\"Analyze patterns in shift bookings\"\"\"\n",
    "        bookings_with_shifts = pd.merge(\n",
    "            bookings_df,\n",
    "            shifts_df[['ID', 'Created At', 'Agent Req', 'Shift Type', 'Charge']],\n",
    "            left_on='Shift ID',\n",
    "            right_on='ID',\n",
    "            how='left',\n",
    "            suffixes=('_booking', '_shift')\n",
    "        )\n",
    "        \n",
    "        bookings_with_shifts['time_to_fill'] = (\n",
    "            pd.to_datetime(bookings_with_shifts['Created At_booking']) - \n",
    "            pd.to_datetime(bookings_with_shifts['Created At_shift'])\n",
    "        ).dt.total_seconds() / 3600\n",
    "        \n",
    "        role_bookings = bookings_with_shifts.groupby('Agent Req').agg({\n",
    "            'Shift ID': 'count',\n",
    "            'time_to_fill': 'mean',\n",
    "            'Charge': 'mean'\n",
    "        }).round(2)\n",
    "        \n",
    "        self.summaries['bookings'] = {\n",
    "            'time_to_fill': bookings_with_shifts['time_to_fill'].describe().to_dict(),\n",
    "            'role_patterns': role_bookings.to_dict()\n",
    "        }\n",
    "        \n",
    "        return bookings_with_shifts\n",
    "\n",
    "    def analyze_economic_impact(self, shifts_df, cancellations_with_shifts):\n",
    "        \"\"\"Analyze economic impact of cancellations\"\"\"\n",
    "        if 'Time' not in cancellations_with_shifts.columns:\n",
    "            cancellations_with_shifts = pd.merge(\n",
    "                cancellations_with_shifts,\n",
    "                shifts_df[['ID', 'Time', 'Charge']],\n",
    "                left_on='Shift ID',\n",
    "                right_on='ID',\n",
    "                how='left'\n",
    "            )\n",
    "\n",
    "        total_revenue = (shifts_df['Charge'] * shifts_df['Time']).sum()\n",
    "        cancelled_revenue = (cancellations_with_shifts['Charge'] * \n",
    "                           cancellations_with_shifts['Time']).sum()\n",
    "        \n",
    "        role_impact = cancellations_with_shifts.groupby('Agent Req').agg({\n",
    "            'Shift ID': 'count',\n",
    "            'Charge': ['mean', 'sum'],\n",
    "            'Time': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        self.summaries['economic'] = {\n",
    "            'total_revenue': total_revenue,\n",
    "            'cancelled_revenue': cancelled_revenue,\n",
    "            'role_impact': role_impact.to_dict()\n",
    "        }\n",
    "        \n",
    "        return role_impact\n",
    "\n",
    "def main():\n",
    "    # Initialize classes\n",
    "    cleaner = DataCleaner()\n",
    "    analyzer = DataAnalyzer()\n",
    "    \n",
    "    # Load data\n",
    "    shifts_df = pd.read_csv('data/cleveland_shifts_large.csv')\n",
    "    bookings_df = pd.read_csv('data/booking_logs_large.csv')\n",
    "    cancellations_df = pd.read_csv('data/cancel_logs_large.csv')\n",
    "    \n",
    "    # Clean data\n",
    "    shifts_df = cleaner.load_and_clean_shifts(shifts_df)\n",
    "    bookings_df = cleaner.load_and_clean_bookings(bookings_df)\n",
    "    cancellations_df = cleaner.load_and_clean_cancellations(cancellations_df)\n",
    "    clean_cancellations, quality_stats = cleaner.clean_lead_times(cancellations_df)\n",
    "    \n",
    "    # Run analyses\n",
    "    cancellations_with_shifts = analyzer.analyze_cancellation_patterns(\n",
    "        clean_cancellations, shifts_df)\n",
    "    bookings_with_shifts = analyzer.analyze_booking_patterns(\n",
    "        bookings_df, shifts_df, clean_cancellations)\n",
    "    role_impact = analyzer.analyze_economic_impact(\n",
    "        shifts_df, cancellations_with_shifts)\n",
    "    \n",
    "    return analyzer.summaries\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CBH_CS2)",
   "language": "python",
   "name": "cbh_cs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
