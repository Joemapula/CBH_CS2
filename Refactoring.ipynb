{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration and Imports ===\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Class to handle data loading and cleaning operations\"\"\"\n",
    "    def __init__(self, data_dir='data'):\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "    def load_file(self, filename):\n",
    "        \"\"\"Safely load CSV file with error handling\"\"\"\n",
    "        try:\n",
    "            filepath = os.path.join(self.data_dir, filename)\n",
    "            return pd.read_csv(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def load_all_datasets(self):\n",
    "        \"\"\"Load all required datasets\"\"\"\n",
    "        datasets = {\n",
    "            'shifts': 'cleveland_shifts_large.csv',\n",
    "            'bookings': 'booking_logs_large.csv',\n",
    "            'cancellations': 'cancel_logs_large.csv'\n",
    "        }\n",
    "        \n",
    "        return {key: self.load_file(filename) \n",
    "                for key, filename in datasets.items()}\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"Class to handle data cleaning operations\"\"\"\n",
    "    @staticmethod\n",
    "    def clean_shifts(df):\n",
    "        if df is None:\n",
    "            return None\n",
    "            \n",
    "        df = df.copy()\n",
    "        datetime_cols = ['Start', 'End', 'Created At']\n",
    "        \n",
    "        for col in datetime_cols:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], format='mixed')\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {col}: {str(e)}\")\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_bookings(df):\n",
    "        if df is None:\n",
    "            return None\n",
    "            \n",
    "        df = df.copy()\n",
    "        try:\n",
    "            df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning bookings: {str(e)}\")\n",
    "            df['Created At'] = pd.to_datetime(df['Created At'], errors='coerce')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_cancellations(df):\n",
    "        if df is None:\n",
    "            return None\n",
    "            \n",
    "        df = df.copy()\n",
    "        try:\n",
    "            df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "            if 'Shift Start Logs' in df.columns:\n",
    "                df['Shift Start Logs'] = pd.to_datetime(df['Shift Start Logs'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning cancellations: {str(e)}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_lead_times(df):\n",
    "        \"\"\"Clean and categorize lead times\"\"\"\n",
    "        if df is None:\n",
    "            return None, None\n",
    "            \n",
    "        df = df.copy()\n",
    "        \n",
    "        # Track data quality\n",
    "        quality_stats = {\n",
    "            'original_rows': len(df),\n",
    "            'null_lead_times': df['Lead Time'].isnull().sum(),\n",
    "            'infinite_values': (~np.isfinite(df['Lead Time'])).sum()\n",
    "        }\n",
    "        \n",
    "        # Remove invalid data\n",
    "        mask = df['Lead Time'].notnull() & np.isfinite(df['Lead Time'])\n",
    "        df = df[mask]\n",
    "        \n",
    "        # Add analysis columns\n",
    "        df['clean_lead_time'] = df['Lead Time']\n",
    "        df['cancellation_category'] = df['clean_lead_time'].apply(\n",
    "            lambda x: DataCleaner.categorize_lead_time(x))\n",
    "        \n",
    "        # Flag extreme values\n",
    "        df['is_extreme_negative'] = df['Lead Time'] < -72\n",
    "        df['is_extreme_positive'] = df['Lead Time'] > 1000\n",
    "        \n",
    "        quality_stats['final_rows'] = len(df)\n",
    "        quality_stats['removed_rows'] = quality_stats['original_rows'] - quality_stats['final_rows']\n",
    "        \n",
    "        return df, pd.Series(quality_stats)\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorize_lead_time(hours):\n",
    "        \"\"\"Categorize lead times based on business rules\"\"\"\n",
    "        if hours < 0:\n",
    "            return 'No-Show'\n",
    "        elif hours < 4:\n",
    "            return 'Late (<4hrs)'\n",
    "        elif hours < 24:\n",
    "            return 'Same Day'\n",
    "        elif hours < 72:\n",
    "            return 'Advance (<3 days)'\n",
    "        return 'Early (3+ days)'\n",
    "\n",
    "class DataAnalyzer:\n",
    "    \"\"\"Class to handle analysis operations\"\"\"\n",
    "    def __init__(self, shifts_df, bookings_df, cancellations_df):\n",
    "        self.shifts_df = shifts_df\n",
    "        self.bookings_df = bookings_df\n",
    "        self.cancellations_df = cancellations_df\n",
    "        self.summary = DataSummary()\n",
    "    \n",
    "    def analyze_shifts(self):\n",
    "        \"\"\"Analyze shifts data\"\"\"\n",
    "        if self.shifts_df is None:\n",
    "            return None\n",
    "            \n",
    "        # Basic statistics\n",
    "        numeric_stats = self.shifts_df[['Charge', 'Time']].describe()\n",
    "        \n",
    "        # Time-based analysis\n",
    "        self.shifts_df['Hour'] = self.shifts_df['Start'].dt.hour\n",
    "        self.shifts_df['Day'] = self.shifts_df['Start'].dt.day_name()\n",
    "        self.shifts_df['Month'] = self.shifts_df['Start'].dt.month\n",
    "        \n",
    "        # Store results\n",
    "        self.summary.add_summary('shifts', 'numeric_stats', numeric_stats)\n",
    "        return numeric_stats\n",
    "    \n",
    "    def analyze_cancellations(self):\n",
    "        \"\"\"Analyze cancellation patterns\"\"\"\n",
    "        if self.cancellations_df is None:\n",
    "            return None\n",
    "            \n",
    "        clean_cancels, stats = DataCleaner.clean_lead_times(self.cancellations_df)\n",
    "        if clean_cancels is None:\n",
    "            return None\n",
    "            \n",
    "        # Analysis results\n",
    "        results = {\n",
    "            'total_cancellations': len(clean_cancels),\n",
    "            'categories': clean_cancels['cancellation_category'].value_counts().to_dict(),\n",
    "            'quality_stats': stats.to_dict()\n",
    "        }\n",
    "        \n",
    "        self.summary.add_summary('cancellations', 'analysis', results)\n",
    "        return results\n",
    "    \n",
    "    def analyze_economic_impact(self):\n",
    "        \"\"\"Analyze economic impact of cancellations\"\"\"\n",
    "        if any(df is None for df in [self.shifts_df, self.cancellations_df]):\n",
    "            return None\n",
    "            \n",
    "        # Calculate revenue metrics\n",
    "        total_revenue = (self.shifts_df['Charge'] * self.shifts_df['Time']).sum()\n",
    "        avg_rate = self.shifts_df['Charge'].mean()\n",
    "        \n",
    "        results = {\n",
    "            'total_revenue': total_revenue,\n",
    "            'average_rate': avg_rate\n",
    "        }\n",
    "        \n",
    "        self.summary.add_summary('economic', 'impact', results)\n",
    "        return results\n",
    "\n",
    "class DataSummary:\n",
    "    \"\"\"Class to store and manage analysis results\"\"\"\n",
    "    def __init__(self):\n",
    "        self.summaries = {}\n",
    "    \n",
    "    def add_summary(self, dataset_name, summary_type, data):\n",
    "        if dataset_name not in self.summaries:\n",
    "            self.summaries[dataset_name] = {}\n",
    "        self.summaries[dataset_name][summary_type] = data\n",
    "    \n",
    "    def get_summary(self, dataset_name, summary_type=None):\n",
    "        if summary_type:\n",
    "            return self.summaries.get(dataset_name, {}).get(summary_type)\n",
    "        return self.summaries.get(dataset_name)\n",
    "    \n",
    "    def print_summary(self, dataset_name):\n",
    "        if dataset_name in self.summaries:\n",
    "            print(f\"\\nSummary for {dataset_name}:\")\n",
    "            for summary_type, data in self.summaries[dataset_name].items():\n",
    "                print(f\"\\n{summary_type}:\")\n",
    "                print(data)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Initialize components\n",
    "    loader = DataLoader()\n",
    "    cleaner = DataCleaner()\n",
    "    \n",
    "    # Load data\n",
    "    datasets = loader.load_all_datasets()\n",
    "    \n",
    "    # Clean data\n",
    "    clean_datasets = {\n",
    "        'shifts': cleaner.clean_shifts(datasets['shifts']),\n",
    "        'bookings': cleaner.clean_bookings(datasets['bookings']),\n",
    "        'cancellations': cleaner.clean_cancellations(datasets['cancellations'])\n",
    "    }\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = DataAnalyzer(**clean_datasets)\n",
    "    \n",
    "    # Run analyses\n",
    "    shift_analysis = analyzer.analyze_shifts()\n",
    "    cancellation_analysis = analyzer.analyze_cancellations()\n",
    "    economic_analysis = analyzer.analyze_economic_impact()\n",
    "    \n",
    "    return analyzer.summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    summary = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CBH_CS2)",
   "language": "python",
   "name": "cbh_cs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
