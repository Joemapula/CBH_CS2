{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the kernel\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Libraries are properly installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "def load_and_clean_bookings(df):\n",
    "    \"\"\"Load and clean booking logs dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    # Convert datetime columns\n",
    "    df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "    # Add any specific cleaning steps\n",
    "    return df\n",
    "\n",
    "def load_and_clean_cancellations(df):\n",
    "    \"\"\"Load and clean cancellation logs dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    # Convert datetime columns\n",
    "    df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "    df['Shift Start Logs'] = pd.to_datetime(df['Shift Start Logs'])\n",
    "    # Add any specific cleaning steps\n",
    "    return df\n",
    "\n",
    "def load_and_clean_shifts(df):\n",
    "    \"\"\"Load and clean shifts dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    # Convert datetime columns\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    df['End'] = pd.to_datetime(df['End'])\n",
    "    df['Created At'] = pd.to_datetime(df['Created At'])\n",
    "    # Add any specific cleaning steps\n",
    "    return df\n",
    "\n",
    "class DataSummary:\n",
    "    \"\"\"Class to store and manage analysis results\"\"\"\n",
    "    def __init__(self):\n",
    "        self.summaries = {}\n",
    "    \n",
    "    def add_summary(self, dataset_name, summary_type, data):\n",
    "        \"\"\"Add summary statistics to storage\"\"\"\n",
    "        if dataset_name not in self.summaries:\n",
    "            self.summaries[dataset_name] = {}\n",
    "        self.summaries[dataset_name][summary_type] = data\n",
    "    \n",
    "    def get_summary(self, dataset_name, summary_type=None):\n",
    "        \"\"\"Retrieve stored summary statistics\"\"\"\n",
    "        if summary_type:\n",
    "            return self.summaries.get(dataset_name, {}).get(summary_type)\n",
    "        return self.summaries.get(dataset_name)\n",
    "    \n",
    "    def print_summary(self, dataset_name):\n",
    "        \"\"\"Print stored summaries for a dataset\"\"\"\n",
    "        if dataset_name in self.summaries:\n",
    "            print(f\"\\nSummary for {dataset_name}:\")\n",
    "            for summary_type, data in self.summaries[dataset_name].items():\n",
    "                print(f\"\\n{summary_type}:\")\n",
    "                print(data)\n",
    "\n",
    "# Initialize summary storage\n",
    "summary = DataSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"\\nFiles in data directory:\", os.listdir('data'))\n",
    "\n",
    "def load_and_clean_shifts(df):\n",
    "    \"\"\"Load and clean shifts dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert datetime columns with flexible parsing\n",
    "    for col in ['Start', 'End', 'Created At']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], format='mixed')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the shifts data\n",
    "shifts_df = pd.read_csv('data/Cleveland_shifts_Sample_100_rows.csv')\n",
    "\n",
    "# Clean the data using our modified helper function\n",
    "shifts_df = load_and_clean_shifts(shifts_df)\n",
    "\n",
    "# Get initial summary\n",
    "print(\"\\nDataset Shape:\", shifts_df.shape)\n",
    "print(\"\\nColumns:\", shifts_df.columns.tolist())\n",
    "print(\"\\nData Types:\\n\", shifts_df.dtypes)\n",
    "print(\"\\nMissing Values:\\n\", shifts_df.isnull().sum())\n",
    "\n",
    "# Store summary in our DataSummary class\n",
    "summary.add_summary('shifts', 'shape', shifts_df.shape)\n",
    "summary.add_summary('shifts', 'dtypes', shifts_df.dtypes)\n",
    "summary.add_summary('shifts', 'missing_values', shifts_df.isnull().sum())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(shifts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numerical columns\n",
    "numeric_stats = shifts_df[['Charge', 'Time']].describe()\n",
    "print(\"\\nNumerical Statistics:\")\n",
    "print(numeric_stats)\n",
    "\n",
    "# Value counts for categorical columns\n",
    "print(\"\\nShift Type Distribution:\")\n",
    "print(shifts_df['Shift Type'].value_counts(dropna=True))\n",
    "\n",
    "print(\"\\nAgent Requirement Distribution:\")\n",
    "print(shifts_df['Agent Req'].value_counts(dropna=True))\n",
    "\n",
    "# Check for data completeness pattern\n",
    "complete_rows = shifts_df.dropna().shape[0]\n",
    "print(f\"\\nComplete rows: {complete_rows} out of {shifts_df.shape[0]}\")\n",
    "\n",
    "# Time-based patterns\n",
    "shifts_df['Hour'] = shifts_df['Start'].dt.hour\n",
    "shifts_df['Day'] = shifts_df['Start'].dt.day_name()\n",
    "\n",
    "print(\"\\nShifts by hour of day:\")\n",
    "print(shifts_df['Hour'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nShifts by day of week:\")\n",
    "print(shifts_df['Day'].value_counts())\n",
    "\n",
    "# Store these results\n",
    "summary.add_summary('shifts', 'numeric_stats', numeric_stats)\n",
    "summary.add_summary('shifts', 'shift_types', shifts_df['Shift Type'].value_counts(dropna=True).to_dict())\n",
    "summary.add_summary('shifts', 'agent_types', shifts_df['Agent Req'].value_counts(dropna=True).to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CBH_CS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
